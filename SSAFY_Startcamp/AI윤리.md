## 인공지능 윤리의 필요성
 #### 원인
> 사람들이 내리던 결정을 인공지능이 내리는 빈도가 많아졌기 때문에 인공지능의 윤리에 대해서 생각해봐야 함.
 #### 인공지능 적용 분야
> IT계열 뿐만 아니라 영화, 미술, 음악, 문학, 법학, 농업, 광고 등에서 사용되며, 우리나라의 경우 특히 제조업 분야에서 인기가 늘어나고 있다.
 #### 인공지능의 장단점

| 장점                | 단점                 |
| ----------------- | ------------------ |
| 인간을 대신하여 편리함을 제공  | 인간의 일자리를 잃게 함      |
| 빠르고 올바른 판단에 도움을 줌 | 인공지능에 의해 감시받거나 종속됨 |
| 개인 비서 역할 담당 가능    | 인간 관계가 줄어들 수 있음.   |
| 업무의 효율과 생산성을 높임   |                    |
#### 인공지능으로 인한 사회적 변화 
> 이미 인공지능이 발전해 우리 삶의 한 부분으로 들어오고 있으므로 장점은 최대화하고 위험은 최소화하도록 파악할 필요가 있음.
	사람에게 요구하던 윤리 기준을 AI 시스템에게도 요구할 필요가 있음.
#### 예시 
> 트롤리 딜레마의 무인자동차 적용
- 직진하면 여러 사람이 죽거나 다치고, 방향을 급격히 꺾으면 차에 타고 있는 운전자만 죽거나 다친다고 할 때
- 무인 자동차는 어떻게 결정해야 하는가? + 자기 희생 모드의 무인자동차 제작 의무화 법률에 찬성하는가? + 그 차를 사겠는가?
	의 3가지 질문에 일관적인 논리를 펼치기 어려움
- => 윤리의식이 없는 인공지능에 대한 고민 필요함!

## 인공지능 윤리의 기본 원칙
1. 데이터 보호와 프라이버시
    1. 정보의 자기결정권
    2. 범위
        1. 개인식별정보: 이름, 주소, 전화번호 등
        2. 비식별정보: 다른 정보와 결합될 경우 식별가능성이 있는 정보
        3. 민감성 정보
        4. 익명화 및 가명처리 된 데이터
    3. 중요한 이유: AI 기술이 발전하면서 데이터 프라이버시가 더욱 취약해져서 ⇒ 가이드라인 필요
        1. 위협사례
            1. 야후 데이터 유출
            2. [Clearview.ai](http://Clearview.ai) 프로필 얼굴사진 무단 수집
            3. AI 음성 인식 비서의 사용자 음성 정보 저장
            4. 배송 기사의 안전 주행 점수 측정을 위해 AI 카메라 설치하여 모니터링
            5. 얼굴인식 AI시스템의 위험성
2. 공정성과 편향
    1. 공정성
        1. AI시스템이 모든 사용자에게 공정하게 서비스를 제공해야 함.
        2. 수집과 모델 학습 과정에서도!!
        3. 이런 것들을 보장하기 위한 기술적 조치마저 필요함.
    2. 편향
        1. AI시스템이 특정 그룹이나 개인에 대해 불공정하게 행동하거나 예측하는 경향
        2. 데이터 편향: 학습데이터 문제
        3. 알고리즘 편향: 특정 변수를 과도하게 강조하거나 구조적 요소에 오류가 있을 때
        4. 사회적 편향: 사회적 편견을 AI가 학습할 경우
3. 책임성과 투명성
    1. 책임성
        1. AI의 결정 및 행동에 대해 인간 개발자와 운영자는 책임을 져야 함.
        2. 설계, 개발 및 배포 등 각 단계마다에!
        3. 책임소재 명확히하고, 수정하고 개선할 수 있는 절차를 마련해야 함.
        4. AI의 결정 과정에 대한 이해와 이의 제기할 수 있는 권리를 사용자에게 보장해야 함.
    2. 투명성
        1. AI의 작동 원리 및 결정 기준은 명확하고 이해하기 쉽게 공개되어야 함.
        2. 사용자가 AI 결정과정을 이해하고, 필요한 경우 검토하거나 문제를 제기할 수 있도록 지원해야 함.
        3. 데이터 처리 및 활용 방식에 대해 사용자에게 충분한 정보를 얻고 동의를 구해야 함.

	- ⇒ 궁극적 목적: AI가 인간을 위해 봉사하는가
### 인공지능 윤리 문제 해결을 위한 사회적 노력
#### 디지털 권리 장전
- 개요
> 디지털 사회의 이해관계인이 가지는 다양한 권리와 의무에 관해 총칙과 각칙을 나열.
- 국가별 노력
	- 한국
		- 대한민국 디지털 권리 장전
	- EU AI Act
		- 2023.12월 AI 위험등급을 부여한 법안
		- 특정 분야의 AI 시스템에 국한되지 않은 기본법으로 AI 리스크 규제
		- 범용 AI를 개발하는 기업은 AI 모델의 학습과정을 보고해야 한다는 내용까지 포함
	- 미국 인공지능 행정명령
		- 2023.10월 AI 행정명령
		- AI 안전성 평가 의무화
		- 도구의 안정성 표준 마련
		- 연방정부에 AI 훈련 사전보고
		- AI 컨텐츠에 대한 워터마크 부착
		- AI 개발과 활용은 촉진하되 국가 안보, 건강과 안전을 위협하는 AI 기술 개발과 이용은 규제
#### 설명할 수 있는 AI
 1. 측정형 기술
 	- 신뢰할 수 있는 AI
	- AI 시스템의 공정성, 성능, 견고함, 개인정보보호 준수 등을 확인하기 위해 데이터 수집, 학습, 평가 등 각 단계마다 AI 윤리 준수 여부를 정량적으로 평가
	- 각 기업이 부담할 수 있는 AI 리스크를 시스템으로 최소화
	- 공정성 평가, 성과 평가, 모델 평가 등을 수치화
 2. 설명가능한 AI
	- 전통적인 컴퓨팅 시스템의 의사결정의 과정은 프로그램 소스코드로 투명하게 표현될 수 있었음에 반해, AI 알고리즘은 뛰어난 판단 능력을 보여주지만, 세부적인 로직을 기존 소스코드처럼 명시하거나 해석하기 어려워 통상 블랙박스에 비유
	- 사용자가 AI가 생성한 결과를 신뢰할 수 있도록 시스템에서 특정 결과를 생성하게 된 과정을 단계별로 설명할 수 있는 AI를 개발
	- AI 모델의 복잡한 블랙박스를 투명하게 보여줌
	- Surrogate Model, SHAP, LIME 방식으로 구현되고 있음.
	- [최근 anthropic에서 발표한 설명가능한 AI 리포트](https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html)
- 기업별 인공지능 윤리 선언
	- [IBM - 책임감 있는 AI에 대한 IBM의 원칙](https://www.ibm.com/kr-ko/impact/ai-ethics)
	- [Google - 우리의 원칙](https://ai.google/responsibility/principles/)
	- Google Cloud의 Vision API에서 성별 라벨 삭제
	- Explainable Al, Model Cards, Tensorflow Opensource toolkit
	- [와중에 OpenAI의 경우 윤리담당자의 해고가 있었음](https://www.chosun.com/economy/tech_it/2024/05/20/L56VCDZV6JHHVFHRIRGA7S617U/)
#### 향후 인공지능의 전망과 윤리 논쟁의 전망?
1. 전문성의 증가
	- 인간 수준의 전문성을 갖춘 인공지능이 증가할 것임.
2. 윤리적 논쟁 증가
	- 인공지능의 발전에 따른 윤리적 문제에 대한 논의와 강화된 관리가 필수적일 것으로 예측됨.
3. 생활 편의의 증가
	- 인공지능 기술의 발전으로 인해 생활의 여러 영역에서 편의성이 크게 증가할 것으로 전망됨.
- 따라서 기술의 발전으로 AI의 사회적 적용이 확대됨에 따라 윤리 논쟁이 증가할 것으로 전망됨.
#### 결론: AI 리터러시를 키우자
- AI가 동작하는 원리를 이해하고, 결과를 해석하며, AI 시스템과 효과적으로 상호작용하는 능력을 키워야 함.
- 책임감 있는 마음을 가지고 AI가 미칠 수 있는 윤리적, 사회적 영향력을 잘 이해하는 능력을 키워야 함.
